name: PyPI publish dbt-spark-submit

# Fires when the release workflow creates a "dbt-spark-submit-v*" GitHub Release.
# hatch-vcs reads the version directly from the git tag â€” no version file is touched.
#
# One-time setup on PyPI (https://pypi.org/manage/account/publishing/):
#   Package name:      dbt-spark-submit
#   Owner:             <your-github-username>
#   Repository:        <your-fork-repo-name>
#   Workflow filename: pypi-publish-dbt-spark-submit.yml
#   Environment name:  pypi

on:
  release:
    types: [published]

jobs:
  build-and-publish:
    name: Build and publish to PyPI
    if: startsWith(github.event.release.tag_name, 'dbt-spark-submit-v')
    runs-on: ubuntu-latest
    environment: pypi
    permissions:
      id-token: write  # required for OIDC trusted publishing
      contents: read

    steps:
      - name: Checkout repository at release tag
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.release.tag_name }}
          fetch-depth: 0  # hatch-vcs needs full tag history to resolve the version

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install hatch and hatch-vcs
        run: pip install --upgrade hatch hatch-vcs

      - name: Show resolved version
        working-directory: dbt-spark
        run: hatch version

      - name: Build wheel and source distribution
        working-directory: dbt-spark
        run: hatch build

      - name: List built artifacts
        working-directory: dbt-spark
        run: ls -lh dist/

      - name: Verify build with twine
        working-directory: dbt-spark
        run: |
          pip install twine
          twine check dist/*

      - name: Publish to PyPI
        uses: pypa/gh-action-pypi-publish@release/v1
        with:
          packages-dir: dbt-spark/dist/
